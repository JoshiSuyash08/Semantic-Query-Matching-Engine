{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOgQKJZArEJO",
        "outputId": "957548cf-abc0-41e9-b358-30059961666a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffYVE2QhrIKj",
        "outputId": "48d420ce-17a1-455d-9b72-2ea694c6ca0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/ColabData/cran\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/My Drive/ColabData/cran"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "raQn3NlFrUAw"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import random\n",
        "import string\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from pprint import pprint\n",
        "# Libraries for visualization\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 326,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ErLvwVnwrORr",
        "outputId": "091c64c5-33d3-46d1-e437-20f8d9026956"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1837\n",
            "1484\n"
          ]
        }
      ],
      "source": [
        "# Load the Cranfield dataset files into Python objects\n",
        "with open('cran.all.1400') as f:\n",
        "    cran_docs = f.read().splitlines()\n",
        "\n",
        "with open('cran.qry') as f:\n",
        "    cran_queries = f.read().splitlines()\n",
        "\n",
        "with open('cranqrel') as f:\n",
        "    cran_relevance = [line.split() for line in f.read().splitlines()]\n",
        "\n",
        "# Convert the relevance list into a pandas DataFrame\n",
        "cran_relevance = pd.DataFrame(cran_relevance, columns=['query_id', 'doc_id', 'relevance'])\n",
        "\n",
        "# print(cran_docs)\n",
        "# print(cran_queries)\n",
        "print(len(cran_relevance))\n",
        "print(len(cran_relevance[cran_relevance['relevance']>'1']))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 328,
      "metadata": {
        "id": "RYKBQqVzzZf-"
      },
      "outputs": [],
      "source": [
        "def load_data():\n",
        "  # read data from CISI.ALL file and store in dictinary\n",
        "  # Open the file for reading\n",
        "  with open('cran.all.1400', 'r') as f:\n",
        "      data = f.read().splitlines()\n",
        "\n",
        "  # Initialize an empty dictionary\n",
        "  doc_dict = {}\n",
        "\n",
        "  # Initialize variables to store the current document ID and text\n",
        "  current_id = None\n",
        "  current_text = ''\n",
        "\n",
        "  # Loop over the list of strings\n",
        "  for line in data:\n",
        "      if line.startswith('.I'):\n",
        "          # If we've already seen a document ID, add the current text to the doc_dict\n",
        "          if current_id is not None:\n",
        "              doc_dict[current_id] = current_text.strip()\n",
        "          # Reset the current text and update the current ID\n",
        "          current_text = ''\n",
        "          current_id = line.split()[1]\n",
        "      elif line.startswith('.T'):\n",
        "          # Remove the \".T\" tag\n",
        "          line = line[2:]\n",
        "          # Append the line to the current text\n",
        "          current_text += line\n",
        "      else:\n",
        "          # Append the line to the current text\n",
        "          current_text += line\n",
        "\n",
        "  # Add the last document to the doc_dict\n",
        "  if current_id is not None:\n",
        "      doc_dict[current_id] = current_text.strip()\n",
        "\n",
        "# Print the resulting doc_dict\n",
        "# print(doc_dict)\n",
        "\n",
        "\n",
        "  # Open the file for reading\n",
        "  with open('cran.qry', 'r') as f:\n",
        "      data = f.read().splitlines()\n",
        "\n",
        "  # Initialize an empty dictionary\n",
        "  qry_dict = {}\n",
        "\n",
        "  # Loop over the list of strings\n",
        "  for i in range(len(data)):\n",
        "      if data[i].startswith('.I'):\n",
        "          # Get the ID number by splitting the string and taking the second element\n",
        "          id_num = data[i].split()[1]\n",
        "      elif data[i].startswith('.W'):\n",
        "          # Join the remaining sentences into a single string\n",
        "          sentence = ' '.join(data[i+1:i+3])\n",
        "          # Add the sentence to the dictionary with the ID number as the key\n",
        "          qry_dict[id_num] = sentence\n",
        "  qry_dict = {str(int(k)): v for k, v in qry_dict.items()}\n",
        "\n",
        "  \n",
        "\n",
        "  # read data from CISI.REL file and store in dictinary\n",
        "  rel_dict = {}\n",
        "  \n",
        "  with open('cranqrel') as f:\n",
        "    doc_rel, qry_rel = set(), set()\n",
        "    for l in f.readlines():\n",
        "      qry_id = l.lstrip(\" \").strip(\"\\n\").split(\"\\t\")[0].split(\" \")[0]\n",
        "      doc_id = l.lstrip(\" \").strip(\"\\n\").split(\"\\t\")[0].split(\" \")[1]\n",
        "      relevance = l.lstrip(\" \").strip(\"\\n\").split(\"\\t\")[0].split(\" \")[2]\n",
        "      if relevance > '1':\n",
        "        qry_rel.add(qry_id)\n",
        "        doc_rel.add(doc_id)\n",
        "\n",
        "        if qry_id in rel_dict:\n",
        "          rel_dict[qry_id].append(doc_id)\n",
        "        else:\n",
        "          rel_dict[qry_id] = []\n",
        "          rel_dict[qry_id].append(doc_id)\n",
        "\n",
        "  \n",
        "  doc_dict = {int(id): doc for (id, doc) in doc_dict.items() if id in doc_rel}\n",
        "  qry_dict = {int(id): qry for (id, qry) in qry_dict.items() if id in qry_rel}\n",
        "  rel_dict = {int(qid): list(map(int, did_lst)) for (qid, did_lst) in rel_dict.items()}\n",
        "  rel_dict = {k: v for k, v in rel_dict.items() if k in qry_dict}\n",
        "\n",
        "\n",
        "  return doc_dict, qry_dict, rel_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 329,
      "metadata": {
        "id": "gJSH5iZn0C2_"
      },
      "outputs": [],
      "source": [
        "doc_dict, qry_dict, rel_dict = load_data()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jOSuRSBEcXLu"
      },
      "outputs": [],
      "source": [
        "doc_dict.keys()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rel_sum = 0\n",
        "for doc_ids in rel_dict.values():\n",
        "  rel_sum += len(doc_ids)\n",
        "print(f'Number of queries = {len(qry_dict)}')\n",
        "print(f'* Example: {qry_dict[1]}')\n",
        "print(f'\\nNumber of documents = {len(doc_dict)}')\n",
        "print(f'* Example: {doc_dict[2]}')\n",
        "print(f'\\nNumber of q-d+ = {rel_sum}')\n",
        "print(f'* Example:', {1: rel_dict[1]})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQtxY05vqDch",
        "outputId": "399532e1-43c7-4871-847e-6a1f215574e2"
      },
      "execution_count": 331,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of queries = 143\n",
            "* Example: what similarity laws must be obeyed when constructing aeroelastic models of heated high speed aircraft .\n",
            "\n",
            "Number of documents = 794\n",
            "* Example: simple shear flow past a flat plate in an incompressible fluid of smallviscosity ..Ating-yili.Bdepartment of aeronautical engineering, rensselaer polytechnicinstitutetroy, n.y..Wsimple shear flow past a flat plate in an incompressible fluid of smallviscosity .in the study of high-speed viscous flow past a two-dimensional body itis usually necessary to consider a curved shock wave emitting from thenose or leading edge of the body .  consequently, there exists aninviscid rotational flow region between the shock wave and the boundarylayer .  such a situation arises, for instance, in the study of thehypersonic viscous flow past a flat plate .  the situation is somewhatdifferent from prandtl's classical boundary-layer problem . in prandtl'soriginal problem the inviscid free stream outside the boundary layer isirrotational while in a hypersonic boundary-layer problem the inviscidfree stream must be considered as rotational .  the possible effects ofvorticity have been recently discussed by ferri and libby .  in thepresent paper, the simple shear flow past a flat plate in a fluid of smallviscosity is investigated .  it can be shown that this problem can againbe treated by the boundary-layer approximation, the only novel featurebeing that the free stream has a constant vorticity .  the discussionhere is restricted to two-dimensional incompressible steady flow .\n",
            "\n",
            "Number of q-d+ = 973\n",
            "* Example: {1: [184, 29, 31, 12, 51, 102, 13, 14, 15, 57, 378, 859, 185, 30, 37, 52, 142, 195, 875, 56, 66, 95, 462, 497, 858, 876, 879, 880]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gVzAoxjLjam",
        "outputId": "77c0703c-5499-4510-ec7f-9ab620dde606"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of queries = 152\n",
            "* Example: what similarity laws must be obeyed when constructing aeroelastic models of heated high speed aircraft .\n",
            "\n",
            "Number of documents = 924\n",
            "* Example: simple shear flow past a flat plate in an incompressible fluid of smallviscosity ..Ating-yili.Bdepartment of aeronautical engineering, rensselaer polytechnicinstitutetroy, n.y..Wsimple shear flow past a flat plate in an incompressible fluid of smallviscosity .in the study of high-speed viscous flow past a two-dimensional body itis usually necessary to consider a curved shock wave emitting from thenose or leading edge of the body .  consequently, there exists aninviscid rotational flow region between the shock wave and the boundarylayer .  such a situation arises, for instance, in the study of thehypersonic viscous flow past a flat plate .  the situation is somewhatdifferent from prandtl's classical boundary-layer problem . in prandtl'soriginal problem the inviscid free stream outside the boundary layer isirrotational while in a hypersonic boundary-layer problem the inviscidfree stream must be considered as rotational .  the possible effects ofvorticity have been recently discussed by ferri and libby .  in thepresent paper, the simple shear flow past a flat plate in a fluid of smallviscosity is investigated .  it can be shown that this problem can againbe treated by the boundary-layer approximation, the only novel featurebeing that the free stream has a constant vorticity .  the discussionhere is restricted to two-dimensional incompressible steady flow .\n",
            "\n",
            "Number of q-d+ = 1837\n",
            "* Example: {1: [184, 29, 31, 12, 51, 102, 13, 14, 15, 57, 378, 859, 185, 30, 37, 52, 142, 195, 875, 56, 66, 95, 462, 497, 858, 876, 879, 880, 486]}\n"
          ]
        }
      ],
      "source": [
        "rel_sum = 0\n",
        "for doc_ids in rel_dict.values():\n",
        "  rel_sum += len(doc_ids)\n",
        "print(f'Number of queries = {len(qry_dict)}')\n",
        "print(f'* Example: {qry_dict[1]}')\n",
        "print(f'\\nNumber of documents = {len(doc_dict)}')\n",
        "print(f'* Example: {doc_dict[2]}')\n",
        "print(f'\\nNumber of q-d+ = {rel_sum}')\n",
        "print(f'* Example:', {1: rel_dict[1]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WIL9W7oItczM"
      },
      "outputs": [],
      "source": [
        "qry_dict.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i5YCYB3YBu5S"
      },
      "outputs": [],
      "source": [
        "rel_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAzSrH8Ezsw8"
      },
      "source": [
        "Preprocess Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 332,
      "metadata": {
        "id": "uGxFP0c8z1JW"
      },
      "outputs": [],
      "source": [
        "# remove all punctuations\n",
        "for k, v in qry_dict.items():\n",
        "  qry_dict[k] = v.translate(str.maketrans('', '', string.punctuation))\n",
        "for k, v in doc_dict.items():\n",
        "  doc_dict[k] = v.translate(str.maketrans('', '', string.punctuation))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 333,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TiwqJv-Kz-ax",
        "outputId": "ab7b61e8-051c-45af-d688-46a47f2365cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query\n",
            "* Example: cant the static deflection shapes be used in predicting flutter in place of vibrational shapes  if so  can we provide a justification by\n",
            "Document\n",
            "* Example: similarity laws for stressing heated wings AtsienhsBj ae scs 20 1953 1Wsimilarity laws for stressing heated wings   it will be shown that the differential equations for a heatedplate with large temperature gradient and for a similar plate atconstant temperature can be made the same by a propermodification of the thickness and the loading for the isothermal plate this fact leads to the result that the stresses in the heated platecan be calculated from measured strains on the unheated plate bya series of relations called the similarity laws   theapplication of this analog theory to solid wings under aerodynamicheating is discussed in detail   the loading on the unheated analogwing is however complicated and involves the novel conceptof feedback and body force loading   the problem of stressinga heated boxwing structure can be solved by the same analogmethod and is briefly discussed \n"
          ]
        }
      ],
      "source": [
        "print('Query')\n",
        "print(f'* Example: {qry_dict[105]}')\n",
        "print('Document')\n",
        "print(f'* Example: {doc_dict[13]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 336,
      "metadata": {
        "id": "Taej35by6uuW"
      },
      "outputs": [],
      "source": [
        "random.seed(500)\n",
        "unrel_dict = {}\n",
        "for q, doc_ids in rel_dict.items():\n",
        "  unrel = [d for d in doc_dict.keys() if d not in doc_ids]\n",
        "  random.shuffle(unrel)\n",
        "  unrel_dict[q] = unrel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 337,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMGKRULM6y2r",
        "outputId": "4c3a493e-da4c-428b-dcad-a50a43c781aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "* Example: {1: [996, 188, 1087, 293, 842, 891, 687, 846, 259, 466, 1134, 249, 683, 593, 305, 1077, 438, 623, 1350, 657, 567, 748, 799, 478, 809, 1076, 302, 720, 574, 1397, 734, 727, 604, 236, 668, 962, 829, 615, 1051, 408, 678, 913, 821, 1150, 571, 914, 62, 777, 257, 1138, 1228, 1157, 1159, 1048, 931, 606, 1018, 785, 594, 1042, 559, 1024, 79, 589, 603, 326, 883, 843, 487, 1392, 1297, 1034, 934, 923, 666, 172, 1257, 834, 23, 48, 807, 775, 932, 794, 989, 1136, 267, 310, 164, 420, 1001, 811, 291, 1035, 196, 1109, 1100, 1101, 797, 1103, 1394, 1356, 458, 602, 1326, 1058, 598, 1111, 1154, 84, 618, 911, 388, 952, 316, 1161, 1188, 1151, 55, 1213, 616, 315, 841, 422, 122, 978, 823, 261, 1019, 1046, 1300, 1131, 294, 1177, 810, 440, 1305, 864, 723, 1304, 1105, 865, 969, 840, 180, 394, 917, 5, 845, 1365, 16, 202, 1106, 776, 1214, 332, 1370, 731, 881, 1302, 564, 46, 769, 163, 437, 205, 277, 311, 215, 1379, 415, 1112, 393, 460, 730, 577, 801, 788, 121, 1107, 725, 276, 44, 481, 105, 25, 585, 169, 1252, 681, 1037, 951, 1395, 992, 926, 621, 216, 68, 263, 400, 93, 927, 588, 314, 1391, 1317, 976, 885, 652, 1274, 1387, 482, 407, 174, 688, 689, 442, 1083, 742, 910, 575, 818, 170, 1306, 427, 541, 1384, 296, 456, 494, 800, 224, 1115, 828, 1068, 1045, 75, 796, 839, 208, 713, 436, 721, 384, 269, 323, 936, 1081, 820, 382, 611, 704, 1345, 335, 213, 492, 1033, 1308, 735, 1364, 212, 308, 790, 1204, 252, 877, 1121, 22, 578, 966, 1361, 804, 873, 825, 987, 946, 476, 1380, 207, 1013, 609, 1084, 1031, 406, 214, 410, 837, 64, 569, 401, 555, 354, 766, 1041, 1347, 805, 63, 155, 329, 395, 722, 789, 709, 318, 866, 505, 803, 985, 1050, 28, 576, 82, 381, 1367, 558, 749, 806, 784, 1052, 150, 416, 419, 682, 253, 527, 99, 192, 1311, 115, 608, 1321, 50, 272, 573, 194, 144, 808, 997, 719, 1032, 514, 232, 916, 712, 552, 1055, 141, 795, 938, 1176, 965, 1030, 197, 540, 639, 433, 629, 304, 741, 1056, 1098, 1059, 2, 423, 94, 565, 1022, 27, 857, 819, 612, 285, 1198, 656, 320, 649, 619, 256, 92, 258, 39, 901, 1174, 412, 418, 968, 838, 21, 268, 250, 187, 1141, 431, 708, 744, 627, 1272, 1185, 370, 605, 676, 698, 650, 1280, 630, 1047, 271, 634, 241, 736, 502, 199, 369, 919, 139, 1346, 1025, 375, 413, 446, 279, 867, 662, 1016, 1062, 1015, 699, 974, 1014, 464, 173, 1243, 469, 1078, 1027, 1363, 1385, 921, 399, 351, 884, 414, 690, 628, 1172, 590, 265, 983, 625, 405, 309, 984, 19, 390, 601, 1383, 324, 306, 990, 733, 887, 475, 935, 503, 909, 950, 817, 449, 772, 234, 848, 553, 273, 225, 793, 336, 724, 317, 1075, 132, 1247, 763, 1366, 1082, 937, 967, 779, 802, 1021, 726, 40, 620, 824, 119, 278, 1362, 706, 995, 554, 1289, 1039, 86, 1010, 970, 836, 1318, 439, 1043, 242, 376, 617, 283, 54, 1044, 1099, 1378, 672, 33, 1108, 380, 659, 622, 925, 661, 88, 648, 499, 1171, 1197, 1381, 181, 41, 110, 980, 1008, 1088, 266, 1085, 981, 971, 389, 1080, 104, 572, 161, 467, 1114, 889, 613, 448, 35, 1355, 65, 468, 1017, 447, 307, 780, 1322, 904, 262, 878, 32, 270, 740, 988, 168, 1259, 338, 1290, 1192, 703, 1344, 1049, 711, 786, 87, 977, 1382, 550, 717, 201, 849, 626, 292, 1104, 1377, 1341, 778, 1339, 894, 998, 1319, 924, 231, 344, 556, 479, 1124, 1386, 680, 1303, 90, 1173, 372, 948, 428, 426, 670, 128, 886, 700, 106, 198, 176, 566, 1187, 1296, 461, 1226, 1135, 1009, 903, 798, 890, 1258, 1122, 728, 596, 686, 701, 658, 3, 986, 1012, 930, 67, 1011, 101, 392, 1316, 746, 1026, 24, 1351, 592, 299, 787, 667, 1264, 247, 874, 920, 1096, 1338, 297, 6, 4, 1310, 899, 1029, 364, 1400, 869, 584, 729, 1295, 562, 470, 465, 870, 166, 1333, 1393, 1146, 360, 47, 1313, 58, 74, 45, 560, 702, 1398, 91, 792, 654, 973, 379, 847, 1061, 544, 999, 679, 239, 111, 691, 663, 557, 677, 868, 123, 1057, 1074, 1256, 1307, 570, 1399, 568, 835, 982, 1023, 1137, 365, 739, 994, 833, 1178, 872, 1054, 1340, 906, 852, 298, 20, 1060, 177, 957, 377, 822, 660, 705, 714, 322, 972, 710, 391, 255, 888, 274, 715, 614, 1097, 826, 643, 160, 97, 597, 743, 459, 655, 409, 36, 200, 1020, 664, 238, 421, 716, 1309, 1110, 522, 856, 1028, 964, 844]}\n"
          ]
        }
      ],
      "source": [
        "print(f'* Example:', {1: unrel_dict[1]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 338,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dee1qRGK62eI",
        "outputId": "db3ae9b9-eba3-4009-a606-b5f094acc347"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of queries in train set: 129\n",
            "Number of queries in validation set: 14\n"
          ]
        }
      ],
      "source": [
        "test_split = int(len(rel_dict) * 0.1)\n",
        "print(f'Number of queries in train set: {len(rel_dict) - test_split}')\n",
        "print(f'Number of queries in validation set: {test_split}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 339,
      "metadata": {
        "id": "g92Uhe3f7P1q"
      },
      "outputs": [],
      "source": [
        "random.seed(500)\n",
        "test_qry_set = random.sample(list(rel_dict.keys()), test_split)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 341,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWs3iUqH7VRz",
        "outputId": "0014ccd4-a030-48aa-b2d3-5dceaf7e6006"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Queries in validation set:\n",
            "[187, 213, 189, 108, 150, 97, 54, 136, 50, 9, 93, 133, 102, 156]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print('Queries in validation set:')\n",
        "print(test_qry_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 342,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "O4t1jesC7aV8",
        "outputId": "4f61866b-bc38-41ac-973b-7f0d30a9a960"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CountVectorizer(analyzer='char_wb', ngram_range=(3, 3))"
            ],
            "text/html": [
              "<style>#sk-container-id-11 {color: black;background-color: white;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer(analyzer=&#x27;char_wb&#x27;, ngram_range=(3, 3))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" checked><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(analyzer=&#x27;char_wb&#x27;, ngram_range=(3, 3))</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 342
        }
      ],
      "source": [
        "word_hashing = CountVectorizer(lowercase=True, analyzer='char_wb', ngram_range=(3,3))\n",
        "word_hashing.fit(list(doc_dict.values()) + list(qry_dict.values()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 343,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qD5gCEIC7htH",
        "outputId": "f83dae9d-04fd-4d79-8631-93de99bb7c49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of letter trigrams: 8501\n",
            "[' 0 ' ' 00' ' 01' ... 'zur' 'zz ' 'zzl']\n"
          ]
        }
      ],
      "source": [
        "wh_size = len(word_hashing.vocabulary_)\n",
        "print(f'Number of letter trigrams: {wh_size}')\n",
        "print(word_hashing.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 344,
      "metadata": {
        "id": "8F_muBZc7l-C"
      },
      "outputs": [],
      "source": [
        "train_set = []\n",
        "for q, doc_ids in rel_dict.items():\n",
        "  if q not in test_qry_set:\n",
        "    for idx, d in enumerate(doc_ids):\n",
        "      sample = [q, d] + unrel_dict[q][idx * 4:(idx + 1) * 4]\n",
        "      train_set.append(sample)\n",
        "train_set = np.array(train_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 345,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kJyO3jb7psU",
        "outputId": "061e8ce5-85b1-404c-e269-245778839458"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Examples of training samples in train set: [q, d+, d1-, d2-, d3-, d4-]\n",
            "array([[   1,  184,  996,  188, 1087,  293],\n",
            "       [   1,   29,  842,  891,  687,  846],\n",
            "       [   1,   31,  259,  466, 1134,  249],\n",
            "       ...,\n",
            "       [ 225, 1074,  420,  379,  400,  198],\n",
            "       [ 225, 1075,  456,  283,  887,  197],\n",
            "       [ 225, 1213,  298,  852,  384,  825]])\n"
          ]
        }
      ],
      "source": [
        "print('Examples of training samples in train set: [q, d+, d1-, d2-, d3-, d4-]')\n",
        "pprint(train_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 353,
      "metadata": {
        "id": "60PGpoCZ713H"
      },
      "outputs": [],
      "source": [
        "doc_id_all = np.array(list(doc_dict.keys()))\n",
        "test_set = []\n",
        "for q in test_qry_set:\n",
        "  for i in range(0, 794, 5):\n",
        "    if i == 790:\n",
        "      test_set.append([q, doc_id_all[i], doc_id_all[i + 1], doc_id_all[i + 2], doc_id_all[i + 3], 0])\n",
        "    else:\n",
        "      test_set.append([q, doc_id_all[i], doc_id_all[i + 1], doc_id_all[i + 2], doc_id_all[i + 3], doc_id_all[i + 4]])\n",
        "doc_dict[0] = ''\n",
        "test_set = np.array(test_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 354,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHUn7_CR9Wfq",
        "outputId": "3feb0c9d-cfe3-4ead-f49d-3238c0fec137"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "array([[ 187,    2,    3,    4,    5,    6],\n",
            "       [ 187,   12,   13,   14,   15,   16],\n",
            "       [ 187,   19,   20,   21,   22,   23],\n",
            "       ...,\n",
            "       [ 156, 1383, 1384, 1385, 1386, 1387],\n",
            "       [ 156, 1391, 1392, 1393, 1394, 1395],\n",
            "       [ 156, 1397, 1398, 1399, 1400,    0]])\n"
          ]
        }
      ],
      "source": [
        "pprint(test_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 355,
      "metadata": {
        "id": "qH4SGyz39ZtX"
      },
      "outputs": [],
      "source": [
        "class DataGeneration(tf.keras.utils.Sequence):\n",
        "  \n",
        "  def __init__(self, dataset, batch_size, wh_model, shuffle=True):\n",
        "    self.data = dataset\n",
        "    self.data_size = len(self.data)\n",
        "    self.indexes = np.arange(self.data_size)\n",
        "    self.batch_size = batch_size\n",
        "    self.wh_model = wh_model\n",
        "    self.shuffle = shuffle\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    # get data in batch\n",
        "    last_index = (idx + 1) * self.batch_size\n",
        "    if last_index < self.data_size:\n",
        "      indexes = self.indexes[idx * self.batch_size:last_index]\n",
        "    else:\n",
        "      indexes = self.indexes[idx * self.batch_size:]\n",
        "    batch_data = self.data[indexes]\n",
        "    # print(batch_data)\n",
        "    # use word hashing to embed data\n",
        "    batch_data_embed = np.zeros((0, 6, wh_size))\n",
        "    for i, row in enumerate(batch_data):\n",
        "      # print(i,\" \",row)\n",
        "      batch_data_embed = np.concatenate([batch_data_embed, tf.expand_dims(self.embed(row), axis=0)], axis=0)\n",
        "    \n",
        "    return batch_data_embed, tf.zeros((batch_data_embed.shape[0], 1))  # y_true is useless in the model\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.data_size // self.batch_size + 1\n",
        "\n",
        "  def on_epoch_end(self):\n",
        "    if self.shuffle:\n",
        "      np.random.RandomState(500).shuffle(self.indexes)\n",
        "\n",
        "  def embed(self, row):\n",
        "    \n",
        "    \n",
        "    row_list = [qry_dict[row[0]]]\n",
        "    # print(row_list)\n",
        "    for i in range(1, 6):\n",
        "      row_list.append(doc_dict[row[i]])\n",
        "    return self.wh_model.transform(row_list).toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 356,
      "metadata": {
        "id": "YDYMlgyJ9hCZ"
      },
      "outputs": [],
      "source": [
        "train = DataGeneration(train_set, batch_size=32, wh_model=word_hashing)\n",
        "test = DataGeneration(test_set, batch_size=32, wh_model=word_hashing)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 357,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDpSTHCEBLPs",
        "outputId": "ed08afac-6c49-4d6f-f91f-54831d1acfa6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 6, 8501)\n",
            "(32, 6, 8501)\n"
          ]
        }
      ],
      "source": [
        "print(train[0][0].shape)\n",
        "print(train[0][0].shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 358,
      "metadata": {
        "id": "fW45qjXzAF1S"
      },
      "outputs": [],
      "source": [
        "# define cosine similarity layer\n",
        "class CosSim(tf.keras.layers.Layer):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "  \n",
        "  def __call__(self, a, b):\n",
        "    dot_product = tf.multiply(tf.math.l2_normalize(a, axis=1), tf.math.l2_normalize(b, axis=1))\n",
        "    return tf.math.reduce_sum(dot_product, axis=1, keepdims=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 359,
      "metadata": {
        "id": "ZPE28VoLALQP"
      },
      "outputs": [],
      "source": [
        "# define DSSM model\n",
        "class DSSM(tf.keras.Model):\n",
        "  \n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.fcn = tf.keras.Sequential(\n",
        "        [tf.keras.layers.Dense(300, activation='tanh'),\n",
        "         tf.keras.layers.Dense(300, activation='tanh'),\n",
        "         tf.keras.layers.Dense(128, activation='tanh')\n",
        "         \n",
        "         ])\n",
        "    self.sim = CosSim()\n",
        "    self.concat = tf.keras.layers.Concatenate(axis=-1)\n",
        "\n",
        "  def call(self, x):\n",
        "    # fully connected layers\n",
        "    q = self.fcn(x[:, 0, :])\n",
        "    d = self.fcn(x[:, 1, :])\n",
        "    d1 = self.fcn(x[:, 2, :])\n",
        "    d2 = self.fcn(x[:, 3, :])\n",
        "    d3 = self.fcn(x[:, 4, :])\n",
        "    d4 = self.fcn(x[:, 5, :])\n",
        "    # cosine similarity\n",
        "    return self.concat([self.sim(q, d), self.sim(q, d1), self.sim(q, d2), self.sim(q, d3), self.sim(q, d4)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 361,
      "metadata": {
        "id": "KZDRC83mAYnT"
      },
      "outputs": [],
      "source": [
        "# define the loss of DSSM\n",
        "class DSSMLoss(tf.keras.losses.Loss):\n",
        "  \n",
        "  def call(self, y_true, y_pred):\n",
        "    return -tf.math.log(tf.nn.softmax(y_pred, axis=-1)[:, 0])\n",
        "\n",
        "# define early stopping\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='loss',\n",
        "    min_delta=0.001,\n",
        "    verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 364,
      "metadata": {
        "id": "gN4636zgAflK"
      },
      "outputs": [],
      "source": [
        "model = DSSM()\n",
        "model.compile(loss=DSSMLoss(), optimizer=tf.optimizers.Adam(learning_rate=0.0005))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 365,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vOGZuBzAiyE",
        "outputId": "a2910fe7-77ea-4bc1-9e03-58138d519ade"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "28/28 [==============================] - 8s 225ms/step - loss: 1.6004\n",
            "Epoch 2/20\n",
            "28/28 [==============================] - 10s 374ms/step - loss: 1.2275\n",
            "Epoch 3/20\n",
            "28/28 [==============================] - 7s 232ms/step - loss: 1.0515\n",
            "Epoch 4/20\n",
            "28/28 [==============================] - 7s 250ms/step - loss: 0.9800\n",
            "Epoch 5/20\n",
            "28/28 [==============================] - 7s 263ms/step - loss: 0.9454\n",
            "Epoch 6/20\n",
            "28/28 [==============================] - 6s 227ms/step - loss: 0.9221\n",
            "Epoch 7/20\n",
            "28/28 [==============================] - 8s 290ms/step - loss: 0.9050\n",
            "Epoch 8/20\n",
            "28/28 [==============================] - 6s 225ms/step - loss: 0.8945\n",
            "Epoch 9/20\n",
            "28/28 [==============================] - 8s 282ms/step - loss: 0.8836\n",
            "Epoch 10/20\n",
            "28/28 [==============================] - 8s 278ms/step - loss: 0.8801\n",
            "Epoch 11/20\n",
            "28/28 [==============================] - 6s 223ms/step - loss: 0.8748\n",
            "Epoch 12/20\n",
            "28/28 [==============================] - 7s 226ms/step - loss: 0.8679\n",
            "Epoch 13/20\n",
            "28/28 [==============================] - 9s 318ms/step - loss: 0.8641\n",
            "Epoch 14/20\n",
            "28/28 [==============================] - 6s 228ms/step - loss: 0.8578\n",
            "Epoch 15/20\n",
            "28/28 [==============================] - 8s 289ms/step - loss: 0.8534\n",
            "Epoch 16/20\n",
            "28/28 [==============================] - 6s 221ms/step - loss: 0.8536\n",
            "Epoch 16: early stopping\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f050bacf010>"
            ]
          },
          "metadata": {},
          "execution_count": 365
        }
      ],
      "source": [
        "model.fit(train, epochs=20, callbacks=[early_stopping])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred = model.predict(test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jizSWCODu0vS",
        "outputId": "32e6badf-8dbf-4dc6-9fdd-fa85d80abd8e"
      },
      "execution_count": 366,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "70/70 [==============================] - 16s 218ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XizWmrqAXSTs",
        "outputId": "f6c1c277-1754-49a4-e563-5858778226da"
      },
      "execution_count": 367,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.40972787, -0.30119526, -0.2633507 ,  0.35643816, -0.455033  ],\n",
              "       [-0.18512891, -0.36305946, -0.36003223, -0.35923648, -0.1860195 ],\n",
              "       [ 0.6846875 , -0.22197965, -0.16595773, -0.38267887, -0.26574323],\n",
              "       ...,\n",
              "       [-0.6465901 , -0.6994611 , -0.73132026,  0.42512578,  0.05461963],\n",
              "       [ 0.14483318,  0.03791783,  0.4882235 ,  0.14992163,  0.15362827],\n",
              "       [-0.21282682, -0.06204201,  0.116076  ,  0.08540961, -0.05545541]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 367
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define average precision (AP)\n",
        "def avg_precision(retrieved_docs, relevant_docs):\n",
        "  tp, fp, sum_precision = 0, 0, 0\n",
        "  for i, doc in enumerate(retrieved_docs):\n",
        "    if doc in relevant_docs:\n",
        "      tp += 1\n",
        "      sum_precision += tp / (tp + fp)\n",
        "    else:\n",
        "      fp += 1\n",
        "  return sum_precision / len(retrieved_docs)"
      ],
      "metadata": {
        "id": "qPdoPOwNu8mT"
      },
      "execution_count": 368,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def ndcg_score(retrieved_docs, relevant_docs, k=None):\n",
        "    \n",
        "    if k is None:\n",
        "        k = len(retrieved_docs)\n",
        "    k = min(k, len(retrieved_docs))\n",
        "\n",
        "    # Calculate the DCG (Discounted Cumulative Gain)\n",
        "    dcg = 0.0\n",
        "    for i in range(k):\n",
        "        doc_id = retrieved_docs[i]\n",
        "        if doc_id in relevant_docs:\n",
        "            rel = 1.0\n",
        "        else:\n",
        "            rel = 0.0\n",
        "        dcg += (2 ** rel - 1) / np.log2(i + 2)\n",
        "\n",
        "    # Calculate the IDCG (Ideal Discounted Cumulative Gain)\n",
        "    ideal_retrieved_docs = sorted(relevant_docs, reverse=True)\n",
        "    idcg = 0.0\n",
        "    for i in range(k):\n",
        "        if i >= len(ideal_retrieved_docs):\n",
        "            break\n",
        "        rel = 1.0\n",
        "        idcg += (2 ** rel - 1) / np.log2(i + 2)\n",
        "\n",
        "    # Calculate the nDCG score\n",
        "    if idcg == 0:\n",
        "        return 0.0\n",
        "    else:\n",
        "        return dcg / idcg\n"
      ],
      "metadata": {
        "id": "MCVDF4ydD3mT"
      },
      "execution_count": 369,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define reciprocal rank (RR)\n",
        "def reciprocal_rank(retrieved_docs, relevant_docs):\n",
        "  rr = 0\n",
        "  for i, doc in enumerate(retrieved_docs):\n",
        "    if doc in relevant_docs:\n",
        "      rr = 1 / (i + 1)\n",
        "      break\n",
        "  return rr"
      ],
      "metadata": {
        "id": "RPNCDDLjvHdj"
      },
      "execution_count": 370,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ap, rr,nd = 0, 0,0\n",
        "test_seg = test_pred.shape[0] // len(test_qry_set)\n",
        "for i, q in enumerate(test_qry_set):\n",
        "  test_pred_q = test_pred[i * test_seg:(i + 1) * test_seg].flatten()[:1162]  # all predictions for each query\n",
        "  retrieved_10_idx = np.argsort(test_pred_q)[::-1][:10]  # reverse sort and get top-10 index\n",
        "  # print(retrieved_10_idx)\n",
        "  # print(rel_dict[q])\n",
        "  ap += avg_precision(doc_id_all[retrieved_10_idx], rel_dict[q])\n",
        "  rr += reciprocal_rank(doc_id_all[retrieved_10_idx], rel_dict[q])\n",
        "  nd += ndcg_score(doc_id_all[retrieved_10_idx], rel_dict[q])\n",
        "print(f'MAP@10: {ap / len(test_qry_set)}')\n",
        "print(f'MRR@10: {rr / len(test_qry_set)}')\n",
        "print(f'NDCG: {nd / len(test_qry_set)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LiVNXpvGvK1a",
        "outputId": "4ad5d69e-aab1-4c62-b750-66f1bdff561b"
      },
      "execution_count": 372,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAP@10: 0.013095238095238094\n",
            "MRR@10: 0.07142857142857142\n",
            "NDCG: 0.027223882437287145\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}